{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### IBM AutoAI-SDK Auto-Generated Notebook v1.13.1\n\n**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered,   \nthere is no guarantee it will successfully execute. This pipeline is optimized for the original dataset.  \nThe pipeline may fail or produce sub-optimium results if used with different data. For different data,  \nplease consider returning to AutoAI Experiments to generate a new pipeline. Please read our documentation   \nfor more information:   \n<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>  \n\n\nBefore modifying the pipeline or trying to re-fit the pipeline, consider:   \nThe notebook converts dataframes to numpy arrays before fitting the pipeline   \n(a current restriction of the preprocessor pipeline). The known_values_list is passed by reference   \nand populated with categorical values during fit of the preprocessing pipeline. Delete its members before re-fitting."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"content\"></a>\n## Notebook content\n\nThis notebook contains steps and code to demonstrate AutoAI pipeline. This notebook introduces commands for getting data,  \npipeline model, model inspection and testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "## Notebook goals\n\n-  inspection of trained pipeline via graphical vizualization and source code preview\n-  pipeline evaluation\n-  pipeline deployment and webservice scoring.\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Setup](#setup)         \n    a.  [AutoAI experiment metadata](#variables_definition)      \n2.\t[Pipeline inspection](#inspection)      \n    a.  [Get historical optimizer instance](#get_hist_and_train)      \n    b.  [Get pipeline model](#get_pipeline)      \n    c.  [Preview pipeline model as python code](#preview_model_to_python_code)      \n    d.  [Visualize pipeline model](#visualize_pipeline)      \n    e.  [Read training data](#train_read)        \n    f.  [Test pipeline model locally](#test_model)       \n3.\t[Pipeline refinery and testing (optional)](#refinery)  \n    a.  [Pipeline definition source code](#pipeline_definition)      \n    b.  [Lale library](#lale_library)      \n4.\t[Deploy and score](#scoring)       \n    a.  [Insert WML credentials](#wml_credentials)   \n    b.  [Create deployment](#deployment)      \n    c.  [Score webservice](#online_scoring)        \n    d.  [Delete deployment](#delete_deployment)       \n5.  [Authors](#authors)      "}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n# Setup\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n - `watson-machine-learning-client` uninstallation of the old client\n - `ibm_watson_machine_learning` installation\n - `autoai-libs` installation/upgrade\n - `lightgbm` or `xgboost` installation/downgrade if they are needed."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip uninstall watson-machine-learning-client -y", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Uninstalling watson-machine-learning-client-1.0.380:\n  Successfully uninstalled watson-machine-learning-client-1.0.380\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U ibm-watson-machine-learning", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting ibm-watson-machine-learning\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/52/791816016fe9a0dfb64eacc264d4c86056f1da513f14da6497c815d6c4ab/ibm_watson_machine_learning-1.0.10-py3-none-any.whl (1.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.4MB 7.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: pandas<=0.25.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (0.24.1)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (2.21.0)\nRequirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (0.3.3)\nRequirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (2020.6.20)\nRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (0.8.2)\nRequirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (1.24.1)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk==2.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson-machine-learning) (2.6.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->ibm-watson-machine-learning) (1.15.4)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->ibm-watson-machine-learning) (2018.9)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->ibm-watson-machine-learning) (2.7.5)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->ibm-watson-machine-learning) (2.8)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->ibm-watson-machine-learning) (3.0.4)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->ibm-watson-machine-learning) (1.12.0)\nRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk==2.6.0->ibm-watson-machine-learning) (0.9.3)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk==2.6.0->ibm-watson-machine-learning) (2.6.0)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk==2.6.0->ibm-watson-machine-learning) (2.6.0)\nRequirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.6.0->ibm-cos-sdk==2.6.0->ibm-watson-machine-learning) (0.14)\nInstalling collected packages: ibm-watson-machine-learning\n  Found existing installation: ibm-watson-machine-learning 1.0.8\n    Uninstalling ibm-watson-machine-learning-1.0.8:\n      Successfully uninstalled ibm-watson-machine-learning-1.0.8\nSuccessfully installed ibm-watson-machine-learning-1.0.10\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U autoai-libs", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Collecting autoai-libs\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/79/2e418d224b1da532f0e98e80c62c874363105a5d1eac2d3fb6a8e6b273ef/autoai_libs-1.11.1-40-cp36-cp36m-manylinux1_x86_64.whl (4.1MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.1MB 6.9MB/s eta 0:00:01\n\u001b[?25hCollecting pandas<1.0.0,>=0.24.2 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.4MB 26.6MB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.16.4 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.5MB 38.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn<0.24.0,>=0.20.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from autoai-libs) (0.20.3)\nRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2018.9)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2.7.5)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn<0.24.0,>=0.20.3->autoai-libs) (1.2.0)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas<1.0.0,>=0.24.2->autoai-libs) (1.12.0)\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, pandas, autoai-libs\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\n  Found existing installation: pandas 0.24.1\n    Uninstalling pandas-0.24.1:\n      Successfully uninstalled pandas-0.24.1\n  Found existing installation: autoai-libs 1.10.5\n    Uninstalling autoai-libs-1.10.5:\n      Successfully uninstalled autoai-libs-1.10.5\nSuccessfully installed autoai-libs-1.11.1 numpy-1.19.1 pandas-0.25.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"variables_definition\"></a>\n### AutoAI experiment metadata\n\nThis cell defines COS credentials required to retrieve AutoAI pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "# @hidden_cell\nfrom ibm_watson_machine_learning.helpers import DataConnection, S3Connection, S3Location\n\ntraining_data_reference = [DataConnection(\n    connection=S3Connection(\n        api_key='R4jV94lbrReAsiI47X9sRmm98wQV_B2KSyv2Qa2W9MKb',\n        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n        endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n    ),\n        location=S3Location(\n        bucket='testeiades7-donotdelete-pr-cbiwmq4utppgnd',\n        path='traning_dataset.csv'\n    ))\n]\ntraining_result_reference = DataConnection(\n    connection=S3Connection(\n        api_key='R4jV94lbrReAsiI47X9sRmm98wQV_B2KSyv2Qa2W9MKb',\n        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n        endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n    ),\n    location=S3Location(\n        bucket='testeiades7-donotdelete-pr-cbiwmq4utppgnd',\n        path='auto_ml/1ca3d34e-c073-46a1-8330-23910088e289/wml_data/201c369e-1e3f-4d4b-8ba6-38af68e530ab/data/automl',\n        model_location='auto_ml/1ca3d34e-c073-46a1-8330-23910088e289/wml_data/201c369e-1e3f-4d4b-8ba6-38af68e530ab/data/automl/cognito_output/Pipeline1/model.pickle',\n        training_status='auto_ml/1ca3d34e-c073-46a1-8330-23910088e289/wml_data/201c369e-1e3f-4d4b-8ba6-38af68e530ab/training-status.json'\n    ))", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Following cell contains input parameters provided to run the AutoAI experiment in Watson Studio"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "experiment_metadata = dict(\n   prediction_type='classification',\n   prediction_column='TARGET',\n   test_size=0.1,\n   scoring='accuracy',\n   project_id='748b5863-dd4e-4c02-85b4-83f9b4dca077',\n   deployment_url='https://eu-gb.ml.cloud.ibm.com',\n   csv_separator=',',\n   random_state=33,\n   excel_sheet=0,\n   max_number_of_estimators=2,\n   training_data_reference = training_data_reference,\n   training_result_reference = training_result_reference)\n\npipeline_name='Pipeline_3'", "execution_count": 5, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"inspection\"></a>\n## Pipeline inspection\nIn this section you will get the trained pipeline model from the AutoAI experiment and inspect it.  \nYou will see pipeline as a pythone code, graphically visualized and at the end, you will perform a local test.\n"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_hist_and_train\"></a>\n### Get historical optimizer instance\n\nThe next cell contains code for retrieving fitted optimizer."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "from ibm_watson_machine_learning.experiment import AutoAI\n\noptimizer = AutoAI().runs.get_optimizer(metadata=experiment_metadata)", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Warning: To use AutoAI with xgboost estimators, you need to have xgboost 0.90 installed.\nWarning: To use AutoAI with lightgbm estimators, you need to have lightgbm 2.2.3 installed.\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_pipeline\"></a>\n### Get pipeline model\n\nThe following cell loads selected AutoAI pipeline model. If you want to get pure scikit-learn pipeline specify `as_type='sklearn'` parameter. By default enriched scikit-learn pipeline is returned `as_type='lale'`."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model = optimizer.get_pipeline(pipeline_name=pipeline_name)", "execution_count": 7, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"preview_model_to_python_code\"></a>\n### Preview pipeline model as python code\nIn the next cell, downloaded pipeline model could be previewed as a python code.  \nYou will be able to see what exact steps are involved in model creation."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.pretty_print(combinators=False, ipython_display=True)", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "```python\nfrom autoai_libs.transformers.exportable import ColumnSelector\nfrom lale.lib.autoai_libs import NumpyColumnSelector\nfrom lale.lib.autoai_libs import CompressStrings\nfrom lale.lib.autoai_libs import NumpyReplaceMissingValues\nfrom lale.lib.autoai_libs import NumpyReplaceUnknownValues\nfrom lale.lib.autoai_libs import boolean2float\nfrom lale.lib.autoai_libs import CatImputer\nfrom lale.lib.autoai_libs import CatEncoder\nimport numpy as np\nfrom lale.lib.autoai_libs import float32_transform\nfrom lale.lib.autoai_libs import TA1\nimport autoai_libs.cognito.transforms.textras_methods\nimport autoai_libs.utils.fc_methods\nfrom lale.lib.autoai_libs import FS1\nfrom lale.lib.autoai_libs import TAM\nfrom lale.lib.sklearn import PCA\nfrom lale.lib.sklearn import DecisionTreeClassifier\nfrom lale.operators import make_pipeline\n\ncolumn_selector = ColumnSelector(columns_indices_list=[7, 8, 9, 10, 11, 12, 13, 14])\nnumpy_column_selector = NumpyColumnSelector(columns=[0, 1, 2, 3, 4, 5, 6, 7])\ncompress_strings = CompressStrings(compress_type='hash', dtypes_list=['int_num', 'int_num', 'int_num', 'int_num', 'int_num', 'int_num', 'int_num', 'int_num'], missing_values_reference_list=['', '-', '?', float('nan')], misslist_list=[[], [], [], [], [], [], [], []])\nnumpy_replace_missing_values = NumpyReplaceMissingValues(filling_values=float('nan'), missing_values=[])\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=float('nan'), filling_values_list=[float('nan'), float('nan'), float('nan'), float('nan'), float('nan'), float('nan'), float('nan'), float('nan')], known_values_list=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 86], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43]], missing_values_reference_list=['', '-', '?', float('nan')])\ncat_imputer = CatImputer(missing_values=float('nan'), sklearn_version_family='20', strategy='most_frequent')\ncat_encoder = CatEncoder(dtype=np.float64, handle_unknown='error', sklearn_version_family='20')\nta1_0 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name='sigmoid', datatypes=['numeric'], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=['Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina', 'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_0 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\nta1_1 = TA1(fun=np.tan, name='tan', datatypes=['float'], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=['Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina', 'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego', 'sigmoid(Original_473)', 'sigmoid(Original_269)', 'sigmoid(Zero)', 'sigmoid(Ma\u00e7\u00e3-Verde)', 'sigmoid(Tangerina)', 'sigmoid(Citrus)', 'sigmoid(A\u00e7a\u00ed-Guaran\u00e1)', 'sigmoid(P\u00eassego)'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_1 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\ntam = TAM(tans_class=PCA(), name='pca', col_names=['Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina', 'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego', 'sigmoid(Original_269)', 'sigmoid(Zero)', 'sigmoid(Ma\u00e7\u00e3-Verde)', 'sigmoid(Tangerina)', 'sigmoid(Citrus)', 'sigmoid(A\u00e7a\u00ed-Guaran\u00e1)', 'sigmoid(P\u00eassego)', 'tan(Original_473)'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_2 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\ndecision_tree_classifier = DecisionTreeClassifier(class_weight='balanced', max_features=None, random_state=33)\npipeline = make_pipeline(column_selector, numpy_column_selector, compress_strings, numpy_replace_missing_values, numpy_replace_unknown_values, boolean2float(), cat_imputer, cat_encoder, float32_transform(), ta1_0, fs1_0, ta1_1, fs1_1, tam, fs1_2, decision_tree_classifier)\n```"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"visualize_pipeline\"></a>\n### Visualize pipeline model\n\nPreview pipeline model stages as graph. Each node's name links to detailed description of the stage.\n"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.visualize()", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<graphviz.dot.Digraph at 0x7f13baec3438>", "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"1725pt\" height=\"102pt\"\n viewBox=\"0.00 0.00 1724.61 101.77\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.7696)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-97.7696 1720.6071,-97.7696 1720.6071,4 -4,4\"/>\n</a>\n</g>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster:tam</title>\n<g id=\"a_clust1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.tam.html\" xlink:title=\"tam = TAM(tans_class=pca, name=&#39;pca&#39;, col_names=[&#39;Original_473&#39;, &#39;Original_269&#39;, &#39;Zero&#39;, &#39;Ma\u00e7\u00e3&#45;Verde&#39;, &#39;Tangerina&#39;, &#39;Citrus&#39;, &#39;A\u00e7a\u00ed&#45;Guaran\u00e1&#39;, &#39;P\u00eassego&#39;, &#39;sigmoid(Original_269)&#39;, &#39;sigmoid(Zero)&#39;, &#39;sigmoid(Ma\u00e7\u00e3&#45;Verde)&#39;, &#39;sigmoid(Tangerina)&#39;, &#39;sigmoid(Citrus)&#39;, &#39;si...)\">\n<polygon fill=\"#ffffff\" stroke=\"#000000\" points=\"1443.7543,-10.7696 1443.7543,-85.7696 1513.7543,-85.7696 1513.7543,-10.7696 1443.7543,-10.7696\"/>\n<text text-anchor=\"middle\" x=\"1478.7543\" y=\"-70.5696\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">TAM</text>\n</a>\n</g>\n</g>\n<!-- column_selector -->\n<g id=\"node1\" class=\"node\">\n<title>column_selector</title>\n<g id=\"a_node1\"><a xlink:title=\"column_selector = ColumnSelector(columns_indices_list=[7, 8, 9, 10, 11, 12, 13, 14])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"39.598\" cy=\"-36.7696\" rx=\"39.6962\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector -->\n<g id=\"node2\" class=\"node\">\n<title>numpy_column_selector</title>\n<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" xlink:title=\"numpy_column_selector = NumpyColumnSelector(columns=[0, 1, 2, 3, 4, 5, 6, 7])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"154.7939\" cy=\"-36.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-45.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-21.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- column_selector&#45;&gt;numpy_column_selector -->\n<g id=\"edge1\" class=\"edge\">\n<title>column_selector&#45;&gt;numpy_column_selector</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M79.2419,-36.7696C87.4778,-36.7696 96.258,-36.7696 104.8101,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.077,-40.2697 115.077,-36.7696 105.0769,-33.2697 105.077,-40.2697\"/>\n</g>\n<!-- compress_strings -->\n<g id=\"node3\" class=\"node\">\n<title>compress_strings</title>\n<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.compress_strings.html\" xlink:title=\"compress_strings = CompressStrings(compress_type=&#39;hash&#39;, dtypes_list=[&#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;], missing_values_reference_list=[&#39;&#39;, &#39;&#45;&#39;, &#39;?&#39;, float(&#39;nan&#39;)], misslist_list=[[], [], [], [], [], [], [], []])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"279.1823\" cy=\"-36.7696\" rx=\"48.5816\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Compress&#45;</text>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Strings</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector&#45;&gt;compress_strings -->\n<g id=\"edge2\" class=\"edge\">\n<title>numpy_column_selector&#45;&gt;compress_strings</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M194.4932,-36.7696C202.6697,-36.7696 211.4456,-36.7696 220.1393,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"220.2662,-40.2697 230.2662,-36.7696 220.2662,-33.2697 220.2662,-40.2697\"/>\n</g>\n<!-- numpy_replace_missing_values -->\n<g id=\"node4\" class=\"node\">\n<title>numpy_replace_missing_values</title>\n<g id=\"a_node4\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" xlink:title=\"numpy_replace_missing_values = NumpyReplaceMissingValues(filling_values=float(&#39;nan&#39;), missing_values=[])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"403.5706\" cy=\"-36.7696\" rx=\"39.6962\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-51.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-15.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- compress_strings&#45;&gt;numpy_replace_missing_values -->\n<g id=\"edge3\" class=\"edge\">\n<title>compress_strings&#45;&gt;numpy_replace_missing_values</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M327.9868,-36.7696C336.4064,-36.7696 345.1697,-36.7696 353.619,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.7256,-40.2697 363.7256,-36.7696 353.7255,-33.2697 353.7256,-40.2697\"/>\n</g>\n<!-- numpy_replace_unknown_values -->\n<g id=\"node5\" class=\"node\">\n<title>numpy_replace_unknown_values</title>\n<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_unknown_values.html\" xlink:title=\"numpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=float(&#39;nan&#39;), filling_values_list=[float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;)], known_values_list=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"525.8377\" cy=\"-36.7696\" rx=\"46.8387\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-51.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Unknown&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-15.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values&#45;&gt;numpy_replace_unknown_values -->\n<g id=\"edge4\" class=\"edge\">\n<title>numpy_replace_missing_values&#45;&gt;numpy_replace_unknown_values</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.2672,-36.7696C451.4865,-36.7696 460.2978,-36.7696 468.9927,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"469.1041,-40.2697 479.104,-36.7696 469.104,-33.2697 469.1041,-40.2697\"/>\n</g>\n<!-- boolean2float -->\n<g id=\"node6\" class=\"node\">\n<title>boolean2float</title>\n<g id=\"a_node6\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.boolean2float.html\" xlink:title=\"boolean2float = boolean2float()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"656.5082\" cy=\"-36.7696\" rx=\"48.0029\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"656.5082\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">boolean2float</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_unknown_values&#45;&gt;boolean2float -->\n<g id=\"edge5\" class=\"edge\">\n<title>numpy_replace_unknown_values&#45;&gt;boolean2float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M572.6436,-36.7696C580.8696,-36.7696 589.5227,-36.7696 598.0197,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.2675,-40.2697 608.2675,-36.7696 598.2674,-33.2697 598.2675,-40.2697\"/>\n</g>\n<!-- cat_imputer -->\n<g id=\"node7\" class=\"node\">\n<title>cat_imputer</title>\n<g id=\"a_node7\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_imputer.html\" xlink:title=\"cat_imputer = CatImputer(missing_values=float(&#39;nan&#39;), sklearn_version_family=&#39;20&#39;, strategy=&#39;most_frequent&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"778.6934\" cy=\"-36.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"778.6934\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"778.6934\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- boolean2float&#45;&gt;cat_imputer -->\n<g id=\"edge6\" class=\"edge\">\n<title>boolean2float&#45;&gt;cat_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M704.799,-36.7696C713.0537,-36.7696 721.6349,-36.7696 729.9025,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"730.159,-40.2697 740.159,-36.7696 730.159,-33.2697 730.159,-40.2697\"/>\n</g>\n<!-- cat_encoder -->\n<g id=\"node8\" class=\"node\">\n<title>cat_encoder</title>\n<g id=\"a_node8\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_encoder.html\" xlink:title=\"cat_encoder = CatEncoder(dtype=np.float64, handle_unknown=&#39;error&#39;, sklearn_version_family=&#39;20&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"891.0609\" cy=\"-36.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"891.0609\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"891.0609\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Encoder</text>\n</a>\n</g>\n</g>\n<!-- cat_imputer&#45;&gt;cat_encoder -->\n<g id=\"edge7\" class=\"edge\">\n<title>cat_imputer&#45;&gt;cat_encoder</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M817.0496,-36.7696C825.1856,-36.7696 833.8781,-36.7696 842.3406,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"842.496,-40.2697 852.496,-36.7696 842.496,-33.2697 842.496,-40.2697\"/>\n</g>\n<!-- float32_transform -->\n<g id=\"node9\" class=\"node\">\n<title>float32_transform</title>\n<g id=\"a_node9\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" xlink:title=\"float32_transform = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1010.4995\" cy=\"-36.7696\" rx=\"45.011\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1010.4995\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"1010.4995\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- cat_encoder&#45;&gt;float32_transform -->\n<g id=\"edge8\" class=\"edge\">\n<title>cat_encoder&#45;&gt;float32_transform</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M929.5095,-36.7696C937.6459,-36.7696 946.3884,-36.7696 955.0125,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"955.0388,-40.2697 965.0388,-36.7696 955.0387,-33.2697 955.0388,-40.2697\"/>\n</g>\n<!-- ta1_0 -->\n<g id=\"node10\" class=\"node\">\n<title>ta1_0</title>\n<g id=\"a_node10\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_0 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name=&#39;sigmoid&#39;, datatypes=[&#39;numeric&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;Original_473&#39;, &#39;Original_269&#39;, &#39;Zero&#39;, &#39;Ma\u00e7\u00e3&#45;Verde&#39;, &#39;Tangerina&#39;, &#39;Citrus...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1118.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1118.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- float32_transform&#45;&gt;ta1_0 -->\n<g id=\"edge9\" class=\"edge\">\n<title>float32_transform&#45;&gt;ta1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1055.782,-36.7696C1064.3371,-36.7696 1073.1951,-36.7696 1081.4698,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1081.5725,-40.2697 1091.5724,-36.7696 1081.5724,-33.2697 1081.5725,-40.2697\"/>\n</g>\n<!-- fs1_0 -->\n<g id=\"node11\" class=\"node\">\n<title>fs1_0</title>\n<g id=\"a_node11\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_0 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1208.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1208.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_0&#45;&gt;fs1_0 -->\n<g id=\"edge10\" class=\"edge\">\n<title>ta1_0&#45;&gt;fs1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1145.7573,-36.7696C1153.782,-36.7696 1162.7209,-36.7696 1171.2852,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1171.4594,-40.2697 1181.4594,-36.7696 1171.4593,-33.2697 1171.4594,-40.2697\"/>\n</g>\n<!-- ta1_1 -->\n<g id=\"node12\" class=\"node\">\n<title>ta1_1</title>\n<g id=\"a_node12\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_1 = TA1(fun=np.tan, name=&#39;tan&#39;, datatypes=[&#39;float&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;Original_473&#39;, &#39;Original_269&#39;, &#39;Zero&#39;, &#39;Ma\u00e7\u00e3&#45;Verde&#39;, &#39;Tangerina&#39;, &#39;Citrus&#39;, &#39;A\u00e7a\u00ed&#45;Guaran\u00e1&#39;, &#39;P\u00eassego&#39;, &#39;sigmoid(Original_473)&#39;,...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1298.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1298.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- fs1_0&#45;&gt;ta1_1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>fs1_0&#45;&gt;ta1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1235.7573,-36.7696C1243.782,-36.7696 1252.7209,-36.7696 1261.2852,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1261.4594,-40.2697 1271.4594,-36.7696 1261.4593,-33.2697 1261.4594,-40.2697\"/>\n</g>\n<!-- fs1_1 -->\n<g id=\"node13\" class=\"node\">\n<title>fs1_1</title>\n<g id=\"a_node13\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_1 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1388.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1388.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_1&#45;&gt;fs1_1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>ta1_1&#45;&gt;fs1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1325.7573,-36.7696C1333.782,-36.7696 1342.7209,-36.7696 1351.2852,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1351.4594,-40.2697 1361.4594,-36.7696 1351.4593,-33.2697 1351.4594,-40.2697\"/>\n</g>\n<!-- pca -->\n<g id=\"node14\" class=\"node\">\n<title>pca</title>\n<g id=\"a_node14\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.pca.html\" xlink:title=\"pca = PCA()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1478.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1478.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">PCA</text>\n</a>\n</g>\n</g>\n<!-- fs1_1&#45;&gt;pca -->\n<g id=\"edge13\" class=\"edge\">\n<title>fs1_1&#45;&gt;pca</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1415.7573,-36.7696C1423.782,-36.7696 1432.7209,-36.7696 1441.2852,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1433.7545,-40.27 1443.7543,-36.7696 1433.7542,-33.27 1433.7545,-40.27\"/>\n</g>\n<!-- fs1_2 -->\n<g id=\"node15\" class=\"node\">\n<title>fs1_2</title>\n<g id=\"a_node15\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_2 = FS1(cols_ids_must_keep=range(0, 8), additional_col_count_to_keep=8)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1568.7543\" cy=\"-36.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1568.7543\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- pca&#45;&gt;fs1_2 -->\n<g id=\"edge14\" class=\"edge\">\n<title>pca&#45;&gt;fs1_2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1513.751,-36.7696C1519.5002,-36.7696 1525.4788,-36.7696 1531.2852,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1531.4594,-40.2697 1541.4594,-36.7696 1531.4593,-33.2697 1531.4594,-40.2697\"/>\n</g>\n<!-- decision_tree_classifier -->\n<g id=\"node16\" class=\"node\">\n<title>decision_tree_classifier</title>\n<g id=\"a_node16\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.decision_tree_classifier.html\" xlink:title=\"decision_tree_classifier = DecisionTreeClassifier(class_weight=&#39;balanced&#39;, max_features=None, random_state=33)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1674.1807\" cy=\"-36.7696\" rx=\"42.3529\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1674.1807\" y=\"-45.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Decision&#45;</text>\n<text text-anchor=\"middle\" x=\"1674.1807\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Tree&#45;</text>\n<text text-anchor=\"middle\" x=\"1674.1807\" y=\"-21.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Classifier</text>\n</a>\n</g>\n</g>\n<!-- fs1_2&#45;&gt;decision_tree_classifier -->\n<g id=\"edge15\" class=\"edge\">\n<title>fs1_2&#45;&gt;decision_tree_classifier</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1595.9042,-36.7696C1603.7097,-36.7696 1612.5018,-36.7696 1621.3002,-36.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1621.5729,-40.2696 1631.5728,-36.7696 1621.5728,-33.2696 1621.5729,-40.2696\"/>\n</g>\n</g>\n</svg>\n"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"train_read\"></a>\n### Read training data\n\nRetrieve training dataset from AutoAI experiment as pandas DataFrame."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "train_df = optimizer.get_data_connections()[0].read()\ntest_df = train_df.sample(n=5).drop([experiment_metadata['prediction_column']], axis=1)", "execution_count": 10, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"test_model\"></a>\n### Test pipeline model locally\nYou can predict target value using trained AutoAI model by calling `predict()`."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "y_pred = pipeline_model.predict(test_df.values)\nprint(y_pred)", "execution_count": 11, "outputs": [{"output_type": "error", "ename": "IndexError", "evalue": "index 14 is out of bounds for axis 1 with size 14", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-11-b70989e6f0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/operators.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_schemas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArrayWithSchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_schemas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#otherwise scorers return zero-dim array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/operators.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2433\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_transform_meta_output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m                     \u001b[0mmeta_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform_meta_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/lale/operators.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0mraw_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             \u001b[0mraw_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s exit  transform %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/autoai_libs/transformers/exportable.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mautoai_libs.transformers.exportable.ColumnSelector.transform\u001b[0;34m()\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/autoai_libs/utils/exportable_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mautoai_libs.utils.exportable_utils.numpy_select_columns\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mIndexError\u001b[0m: index 14 is out of bounds for axis 1 with size 14"]}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"refinery\"></a>\n## Pipeline refinery and testing (optional)\n\nIn this section you will learn how to refine and retrain the best pipeline returned by AutoAI.\nIt can be performed by:\n - modifying pipeline definition source code\n - using [lale](https://lale.readthedocs.io/en/latest/) library for semi-automated data science\n\n**Note**: In order to run this section change following cells to 'code' cell."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"pipeline_definition\"></a>\n### Pipeline definition source code\nFollowing cell lets you experiment with pipeline definition in python, e.g. change steps parameters.\n\nIt will inject pipeline definition to the next cell."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "pipeline_model.pretty_print(combinators=False, ipython_display='input')"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"lale_library\"></a>\n### Lale library\n\n**Note**: This is only an exemplary usage of lale package. You can import more different estimators to refine downloaded pipeline model."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Import estimators"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "raw", "source": "from sklearn.linear_model import LogisticRegression as E1\nfrom sklearn.tree import DecisionTreeClassifier as E2\nfrom sklearn.neighbors import KNeighborsClassifier as E3\nfrom lale.lib.lale import Hyperopt\nfrom lale.operators import TrainedPipeline\nfrom lale import wrap_imported_operators\nfrom lale.helpers import import_from_sklearn_pipeline\nwrap_imported_operators()"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"decomposition_definition\"></a>\n#### Pipeline decomposition and new definition\nIn this step the last stage from pipeline is removed."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "prefix = pipeline_model.remove_last().freeze_trainable()\nprefix.visualize()"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "raw", "source": "new_pipeline = prefix >> (E1 | E2 | E3)\nnew_pipeline.visualize()"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"new_optimizer\"></a>\n#### New optimizer `hyperopt` configuration and training\n\nThis section can introduce other results than the original one and it should be used\nby more advanced users.\n\nNew pipeline is re-trained by passing train data to it and calling `fit` method.\n\nFollowing cell performs dataset split for refined pipeline model."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "from sklearn.model_selection import train_test_split\n\ntrain_X = train_df.drop([experiment_metadata['prediction_column']], axis=1).values\ntrain_y = train_df[experiment_metadata['prediction_column']].values\n\ntrain_X, test_X, train_y, test_y = train_test_split(train_X, train_y, test_size=experiment_metadata['test_size'],\n                                                    stratify=train_y, random_state=experiment_metadata['random_state'])"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "hyperopt = Hyperopt(estimator=new_pipeline, cv=3, max_evals=20)\nfitted_hyperopt = hyperopt.fit(train_X, train_y)"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "hyperopt_pipeline = fitted_hyperopt.get_pipeline()\nnew_pipeline = hyperopt_pipeline.export_to_sklearn_pipeline()"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "prediction = new_pipeline.predict(test_X)"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "from sklearn.metrics import accuracy_score\n\nscore = accuracy_score(y_true=test_y, y_pred=prediction)\nprint('accuracy_score: ', score)"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"scoring\"></a>\n## Deploy and Score\n\nIn this section you will learn how to deploy and score pipeline model as webservice using WML instance."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"wml_credentials\"></a>\n### Connection to WML\nAuthenticate the Watson Machine Learning service on IBM Cloud.\n\n**Tip**: Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n\n**Note:** You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n\n**Action**: Enter your `api_key` in the following cell."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "api_key = \"PUT_YOUR_API_KEY_HERE\"\n\nwml_credentials = {\n  \"apikey\": api_key,\n  \"url\": experiment_metadata[\"deployment_url\"]\n}", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployment\"></a>\n\n### Create deployment\n **Action**: If you want to deploy refined pipeline please change the `pipeline_model` to\n`new_pipeline`.\nIf you prefer you can also change the `deployment_name`.\nTo perform deployment please specify `target_space_id`\n"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "target_space_id = \"PUT_YOUR_TARGET_SPACE_ID_HERE\"\n\nfrom ibm_watson_machine_learning.deployment import WebService\nservice = WebService(target_wml_credentials=wml_credentials,\n                     target_space_id=target_space_id)\nservice.create(\nmodel=pipeline_model,\nmetadata=experiment_metadata,\ndeployment_name=f'{pipeline_name}_webservice'\n)", "execution_count": 13, "outputs": [{"output_type": "error", "ename": "ApiRequestFailure", "evalue": "Error during getting IAM Token. (POST https://iam.cloud.ibm.com/oidc/token)\nStatus code: 400, body: {\"errorCode\":\"BXNIM0415E\",\"errorMessage\":\"Provided API key could not be found\",\"context\":{\"requestId\":\"6019bd7faa324fd583b2474a88573fb9\",\"requestType\":\"incoming.OIDC_Token\",\"userAgent\":\"python-requests/2.21.0\",\"url\":\"https://iam.cloud.ibm.com\",\"instanceId\":\"iamid-5.9-8495-d6b2af6-6757477c84-sf6xw\",\"threadId\":\"190ebe\",\"host\":\"iamid-5.9-8495-d6b2af6-6757477c84-sf6xw\",\"startTime\":\"09.09.2020 17:38:21:749 GMT\",\"endTime\":\"09.09.2020 17:38:21:827 GMT\",\"elapsedTime\":\"78\",\"locale\":\"en_US\",\"clusterName\":\"iam-id-prfra04-h7e1\"}}", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mApiRequestFailure\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-13-1522c5e478cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mibm_watson_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m service = WebService(target_wml_credentials=wml_credentials,\n\u001b[0;32m----> 5\u001b[0;31m                      target_space_id=target_space_id)\n\u001b[0m\u001b[1;32m      6\u001b[0m service.create(\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/deployment/web_service.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_wml_credentials, source_project_id, source_space_id, target_wml_credentials, target_project_id, target_space_id, wml_credentials, project_id, space_id)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 self._target_workspace = WorkSpace(wml_credentials=target_wml_credentials.copy(),\n\u001b[1;32m    106\u001b[0m                                                    \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_project_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                                                    space_id=target_space_id)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# note: only if user provides target WML information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/workspace/workspace.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wml_credentials, project_id, space_id)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# --- end note\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwml_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPIClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwml_credentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwml_credentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwml_credentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'instance_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wml_credentials, project_id)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLOUD_PLATFORM_SPACES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServiceInstanceNewPlan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/instance_new_plan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAMS_URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                  )\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwml_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Successfully prepared token: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwml_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# ml_repository_client is initialized in repo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/instance_new_plan.py\u001b[0m in \u001b[0;36m_create_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wml_credentials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_IAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_IAM_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apikey for IAM token is not provided in credentials for the client.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/ibm_watson_machine_learning/instance_new_plan.py\u001b[0m in \u001b[0;36m_get_IAM_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'access_token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Error during getting IAM Token.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mApiRequestFailure\u001b[0m: Error during getting IAM Token. (POST https://iam.cloud.ibm.com/oidc/token)\nStatus code: 400, body: {\"errorCode\":\"BXNIM0415E\",\"errorMessage\":\"Provided API key could not be found\",\"context\":{\"requestId\":\"6019bd7faa324fd583b2474a88573fb9\",\"requestType\":\"incoming.OIDC_Token\",\"userAgent\":\"python-requests/2.21.0\",\"url\":\"https://iam.cloud.ibm.com\",\"instanceId\":\"iamid-5.9-8495-d6b2af6-6757477c84-sf6xw\",\"threadId\":\"190ebe\",\"host\":\"iamid-5.9-8495-d6b2af6-6757477c84-sf6xw\",\"startTime\":\"09.09.2020 17:38:21:749 GMT\",\"endTime\":\"09.09.2020 17:38:21:827 GMT\",\"elapsedTime\":\"78\",\"locale\":\"en_US\",\"clusterName\":\"iam-id-prfra04-h7e1\"}}"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "Deployment object could be printed to show basic information:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "print(service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To be able to show all available information about deployment use `.get_params()` method:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "service.get_params()", "execution_count": null, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"online_scoring\"></a>\n### Score webservice\nYou can make scoring request by calling `score()` on deployed pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "predictions = service.score(payload=test_df)\npredictions", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to work with the webservice in external Python application you can retrieve the service object by:\n - initialize service by:\n```\n service = WebService(target_wml_credentials=wml_credentials,\n                      target_space_id=target_space_id)\n```\n - get deployment_id by `service.list()` method\n - get webservice object by `service.get('deployment_id')` method\n\nAfter that you can call `service.score()` method."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"delete_deployment\"></a>\n### Delete deployment\n\nYou can delete an existing deployment by calling `service.delete()`."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"authors\"></a>\n### Authors\n\nLicensed Materials - Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs  \n(or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms),  \nsuch agreements located in the link below. Specifically, the Source Components and Sample Materials clause  \nincluded in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BHU2B7&title=IBM%20Watson%20Studio%20Auto-generated%20Notebook%20V2.1\">License Terms</a>  \n\n___"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}